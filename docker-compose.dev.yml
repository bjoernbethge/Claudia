# Docker Compose for Development Services
# This file sets up all required services for local development

services:
  # Ollama - Local LLM inference server
  ollama:
    image: ollama/ollama:latest
    container_name: claudia-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # SearXNG - Privacy-respecting metasearch engine
  searxng:
    image: searxng/searxng:latest
    container_name: claudia-searxng
    ports:
      - "8080:8080"
    volumes:
      - searxng-data:/etc/searxng
    environment:
      - SEARXNG_BASE_URL=http://localhost:8080
      - SEARXNG_SECRET_KEY=${SEARXNG_SECRET_KEY:-changeme-generate-random-key}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  # DuckDB - Analytical Database with Query.Farm Extensions
  duckdb:
    image: python:3.12-slim
    container_name: claudia-duckdb
    ports:
      - "9999:9999"    # HTTP API (if httpserver extension is used)
    volumes:
      - duckdb-data:/data
      - ./duckdb:/app/duckdb:ro
    working_dir: /app
    command: >
      bash -c "
        pip install --quiet duckdb httpx uvicorn fastapi &&
        python -c \"
import duckdb
import os

db_path = '/data/claudia.db'
conn = duckdb.connect(db_path)

# Run init script
with open('/app/duckdb/init.sql', 'r') as f:
    for statement in f.read().split(';'):
        statement = statement.strip()
        if statement:
            try:
                conn.execute(statement)
            except Exception as e:
                print(f'Warning: {e}')

print(f'DuckDB initialized at {db_path}')

# List loaded extensions
result = conn.execute('SELECT extension_name, loaded FROM duckdb_extensions() WHERE loaded = true').fetchall()
print(f'Loaded extensions: {[r[0] for r in result]}')

conn.close()

# Keep container running
import time
while True:
    time.sleep(3600)
\"
      "
    environment:
      - DUCKDB_DATABASE=/data/claudia.db
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import duckdb; duckdb.connect('/data/claudia.db').execute('SELECT 1')"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - default

  # SurrealDB - Multi-model database
  surrealdb:
    image: surrealdb/surrealdb:latest
    container_name: claudia-surrealdb
    ports:
      - "8081:8000"
    volumes:
      - surrealdb-data:/data
    command: start --user root --pass ${SURREALDB_ROOT_PASSWORD:-root} file:/data/database.db
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Note: Ollama already provides an OpenAI-compatible API endpoint at /v1
  # This service is optional and can be used if you need additional proxy features
  # To use Ollama's built-in OpenAI compatibility, just use http://localhost:11434/v1

volumes:
  ollama-data:
    driver: local
  searxng-data:
    driver: local
  surrealdb-data:
    driver: local
  duckdb-data:
    driver: local

networks:
  default:
    name: claudia-network
    driver: bridge
